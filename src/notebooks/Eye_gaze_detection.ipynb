{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctwBWSzqsBg8"
      },
      "source": [
        "Acknowledgements: https://github.com/swook/GazeML\n",
        "\n",
        "The notebook was adapted from this work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uWc8MtxQdLi"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJURwrpBedvc",
        "outputId": "f7672118-3d5b-4013-a426-849743fc05ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sio\n",
            "  Downloading sio-0.1.0-py3-none-any.whl (2.5 kB)\n",
            "Collecting shortio>=0.1.0\n",
            "  Downloading shortio-0.1.0-py3-none-any.whl (4.9 kB)\n",
            "Installing collected packages: shortio, sio\n",
            "Successfully installed shortio-0.1.0 sio-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRFq8FmrIp98"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import cv2\n",
        "import argparse\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "import cv2 as cv\n",
        "from typing import Optional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import glob\n",
        "import json\n",
        "import sio\n",
        "\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV8g9qXzS8Yc"
      },
      "source": [
        "## Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIpQGN5Bspb3",
        "outputId": "3f045177-5745-4ab6-8455-a8aac3e5b180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7HM2FbMtolH",
        "outputId": "f4e78944-dfdf-4d0f-e032-98f45b03d5f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ],
      "source": [
        "%cd drive/My Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a4d_XOBHW1H"
      },
      "outputs": [],
      "source": [
        "# !gdown 13KJi8Ohbxp5q2hGoaS6tzrA_Ejdshafs\n",
        "# !gdown 1wqTA4gutC-L4h8TcMMQO_3jJYBL15-h3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un6gzQtBTAC5"
      },
      "outputs": [],
      "source": [
        "# !unzip imgs.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqusqirwOG3O"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGcVm5C9MEI6"
      },
      "outputs": [],
      "source": [
        "\"\"\"Utility methods for gaze angle and error calculations.\"\"\"\n",
        "\n",
        "def pitchyaw_to_vector(pitchyaws):\n",
        "    n = pitchyaws.shape[0]\n",
        "    sin = np.sin(pitchyaws)\n",
        "    cos = np.cos(pitchyaws)\n",
        "    out = np.empty((n, 3))\n",
        "    out[:, 0] = np.multiply(cos[:, 0], sin[:, 1])\n",
        "    out[:, 1] = sin[:, 0]\n",
        "    out[:, 2] = np.multiply(cos[:, 0], cos[:, 1])\n",
        "    return out\n",
        "\n",
        "\n",
        "def vector_to_pitchyaw(vectors):\n",
        "    n = vectors.shape[0]\n",
        "    out = np.empty((n, 2))\n",
        "    vectors = np.divide(vectors, np.linalg.norm(vectors, axis=1).reshape(n, 1))\n",
        "    out[:, 0] = np.arcsin(vectors[:, 1])  # theta\n",
        "    out[:, 1] = np.arctan2(vectors[:, 0], vectors[:, 2])  # phi\n",
        "    return out\n",
        "\n",
        "radians_to_degrees = 180.0 / np.pi\n",
        "\n",
        "\n",
        "def angular_error(a, b):\n",
        "    \"\"\"Calculate angular error (via cosine similarity).\"\"\"\n",
        "    a = pitchyaw_to_vector(a) if a.shape[1] == 2 else a\n",
        "    b = pitchyaw_to_vector(b) if b.shape[1] == 2 else b\n",
        "\n",
        "    ab = np.sum(np.multiply(a, b), axis=1)\n",
        "    a_norm = np.linalg.norm(a, axis=1)\n",
        "    b_norm = np.linalg.norm(b, axis=1)\n",
        "\n",
        "    # Avoid zero-values (to avoid NaNs)\n",
        "    a_norm = np.clip(a_norm, a_min=1e-7, a_max=None)\n",
        "    b_norm = np.clip(b_norm, a_min=1e-7, a_max=None)\n",
        "\n",
        "    similarity = np.divide(ab, np.multiply(a_norm, b_norm))\n",
        "\n",
        "    return np.arccos(similarity) * radians_to_degrees\n",
        "\n",
        "\n",
        "def mean_angular_error(a, b):\n",
        "    \"\"\"Calculate mean angular error (via cosine similarity).\"\"\"\n",
        "    return np.mean(angular_error(a, b))\n",
        "\n",
        "\n",
        "def draw_gaze(image_in, eye_pos, pitchyaw, length=40.0, thickness=2, color=(0, 0, 255)):\n",
        "    \"\"\"Draw gaze angle on given image with a given eye positions.\"\"\"\n",
        "    image_out = image_in\n",
        "    if len(image_out.shape) == 2 or image_out.shape[2] == 1:\n",
        "        image_out = cv.cvtColor(image_out, cv.COLOR_GRAY2BGR)\n",
        "    dx = -length * np.sin(pitchyaw[1])\n",
        "    dy = length * np.sin(pitchyaw[0])\n",
        "    cv.arrowedLine(image_out, tuple(np.round(eye_pos).astype(np.int32)),\n",
        "                   tuple(np.round([eye_pos[0] + dx, eye_pos[1] + dy]).astype(int)), color,\n",
        "                   thickness, cv.LINE_AA, tipLength=0.2)\n",
        "    return image_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6MkbOMnopXn"
      },
      "outputs": [],
      "source": [
        "def preprocess_unityeyes_image(img, json_data):\n",
        "    ow = 160\n",
        "    oh = 96\n",
        "    # Prepare to segment eye image\n",
        "    ih, iw = img.shape[:2]\n",
        "    ih_2, iw_2 = ih/2.0, iw/2.0\n",
        "\n",
        "    heatmap_w = int(ow/2)\n",
        "    heatmap_h = int(oh/2)\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    def process_coords(coords_list):\n",
        "        coords = [eval(l) for l in coords_list]\n",
        "        return np.array([(x, ih-y, z) for (x, y, z) in coords])\n",
        "    \n",
        "    interior_landmarks = process_coords(json_data['interior_margin_2d'])\n",
        "    caruncle_landmarks = process_coords(json_data['caruncle_2d'])\n",
        "    iris_landmarks = process_coords(json_data['iris_2d'])\n",
        "\n",
        "    left_corner = np.mean(caruncle_landmarks[:, :2], axis=0)\n",
        "    right_corner = interior_landmarks[8, :2]\n",
        "    eye_width = 1.5 * abs(left_corner[0] - right_corner[0])\n",
        "    eye_middle = np.mean([np.amin(interior_landmarks[:, :2], axis=0),\n",
        "                          np.amax(interior_landmarks[:, :2], axis=0)], axis=0)\n",
        "\n",
        "    # Normalize to eye width.\n",
        "    scale = ow/eye_width\n",
        "\n",
        "    translate = np.asmatrix(np.eye(3))\n",
        "    translate[0, 2] = -eye_middle[0] * scale\n",
        "    translate[1, 2] = -eye_middle[1] * scale\n",
        "\n",
        "    rand_x = np.random.uniform(low=-10, high=10)\n",
        "    rand_y = np.random.uniform(low=-10, high=10)\n",
        "    recenter = np.asmatrix(np.eye(3))\n",
        "    recenter[0, 2] = ow/2 + rand_x\n",
        "    recenter[1, 2] = oh/2 + rand_y\n",
        "\n",
        "    scale_mat = np.asmatrix(np.eye(3))\n",
        "    scale_mat[0, 0] = scale\n",
        "    scale_mat[1, 1] = scale\n",
        "\n",
        "    angle = 0 #np.random.normal(0, 1) * 20 * np.pi/180\n",
        "    rotation = R.from_rotvec([0, 0, angle]).as_matrix()\n",
        "\n",
        "    transform = recenter * rotation * translate * scale_mat\n",
        "    transform_inv = np.linalg.inv(transform)\n",
        "    \n",
        "    # Apply transforms\n",
        "    eye = cv2.warpAffine(img, transform[:2], (ow, oh))\n",
        "\n",
        "    rand_blur = np.random.uniform(low=0, high=20)\n",
        "    eye = cv2.GaussianBlur(eye, (5, 5), rand_blur)\n",
        "\n",
        "    # Normalize eye image\n",
        "    eye = cv2.equalizeHist(eye)\n",
        "    eye = eye.astype(np.float32)\n",
        "    eye = eye / 255.0\n",
        "\n",
        "    # Gaze\n",
        "    # Convert look vector to gaze direction in polar angles\n",
        "    look_vec = np.array(eval(json_data['eye_details']['look_vec']))[:3].reshape((1, 3))\n",
        "    #look_vec = np.matmul(look_vec, rotation.T)\n",
        "\n",
        "    gaze = vector_to_pitchyaw(-look_vec).flatten()\n",
        "    gaze = gaze.astype(np.float32)\n",
        "\n",
        "    iris_center = np.mean(iris_landmarks[:, :2], axis=0)\n",
        "\n",
        "    landmarks = np.concatenate([interior_landmarks[:, :2],  # 8\n",
        "                                iris_landmarks[::2, :2],  # 8\n",
        "                                iris_center.reshape((1, 2)),\n",
        "                                [[iw_2, ih_2]],  # Eyeball center\n",
        "                                ])  # 18 in total\n",
        "\n",
        "    landmarks = np.asmatrix(np.pad(landmarks, ((0, 0), (0, 1)), 'constant', constant_values=1))\n",
        "    landmarks = np.asarray(landmarks * transform[:2].T) * np.array([heatmap_w/ow, heatmap_h/oh])\n",
        "    landmarks = landmarks.astype(np.float32)\n",
        "\n",
        "    # Swap columns so that landmarks are in (y, x), not (x, y)\n",
        "    # This is because the network outputs landmarks as (y, x) values.\n",
        "    temp = np.zeros((34, 2), dtype=np.float32)\n",
        "    temp[:, 0] = landmarks[:, 1]\n",
        "    temp[:, 1] = landmarks[:, 0]\n",
        "    landmarks = temp\n",
        "\n",
        "    heatmaps = get_heatmaps(w=heatmap_w, h=heatmap_h, landmarks=landmarks)\n",
        "\n",
        "    assert heatmaps.shape == (34, heatmap_h, heatmap_w)\n",
        "\n",
        "    return {\n",
        "        'img': eye,\n",
        "        'transform': np.asarray(transform),\n",
        "        'transform_inv': np.asarray(transform_inv),\n",
        "        'eye_middle': np.asarray(eye_middle),\n",
        "        'heatmaps': np.asarray(heatmaps),\n",
        "        'landmarks': np.asarray(landmarks),\n",
        "        'gaze': np.asarray(gaze)\n",
        "    }\n",
        "\n",
        "\n",
        "def gaussian_2d(w, h, cx, cy, sigma=1.0):\n",
        "    \"\"\"Generate heatmap with single 2D gaussian.\"\"\"\n",
        "    xs, ys = np.meshgrid(\n",
        "        np.linspace(0, w - 1, w, dtype=np.float32),\n",
        "        np.linspace(0, h - 1, h, dtype=np.float32)\n",
        "    )\n",
        "\n",
        "    assert xs.shape == (h, w)\n",
        "    alpha = -0.5 / (sigma ** 2)\n",
        "    heatmap = np.exp(alpha * ((xs - cx) ** 2 + (ys - cy) ** 2))\n",
        "    return heatmap\n",
        "\n",
        "\n",
        "def get_heatmaps(w, h, landmarks):\n",
        "    heatmaps = []\n",
        "    for (y, x) in landmarks:\n",
        "        heatmaps.append(gaussian_2d(w, h, cx=x, cy=y, sigma=2.0))\n",
        "    return np.array(heatmaps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jVh4FFWoDdw"
      },
      "outputs": [],
      "source": [
        "class UnityEyesDataset(Dataset):\n",
        "\n",
        "    def __init__(self, img_dir: Optional[str] = None):\n",
        "\n",
        "        if img_dir is None:\n",
        "            img_dir = os.path.join(os.getcwd(), '/imgs')\n",
        "\n",
        "        self.img_paths = glob.glob(os.path.join(img_dir, '*.jpg'))\n",
        "        self.img_paths = sorted(self.img_paths, key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
        "        self.json_paths = []\n",
        "        for img_path in self.img_paths:\n",
        "            idx = os.path.splitext(os.path.basename(img_path))[0]\n",
        "            self.json_paths.append(os.path.join(img_dir, f'{idx}.json'))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        full_img = cv2.imread(self.img_paths[idx])\n",
        "        with open(self.json_paths[idx]) as f:\n",
        "            json_data = json.load(f)\n",
        "\n",
        "        eye_sample = preprocess_unityeyes_image(full_img, json_data)\n",
        "        sample = {'full_img': full_img, 'json_data': json_data }\n",
        "        sample.update(eye_sample)\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70P6KGb7n0u-"
      },
      "outputs": [],
      "source": [
        "class MPIIGaze(Dataset):\n",
        "\n",
        "    def __init__(self, mpii_dir: str = 'datasets/MPIIGaze'):\n",
        "\n",
        "        self.mpii_dir = mpii_dir\n",
        "\n",
        "        eval_files = glob.glob(f'{mpii_dir}/Evaluation Subset/sample list for eye image/*.txt')\n",
        "\n",
        "        self.eval_entries = []\n",
        "        for ef in eval_files:\n",
        "            person = os.path.splitext(os.path.basename(ef))[0]\n",
        "            with open(ef) as f:\n",
        "                lines = f.readlines()\n",
        "                for line in lines:\n",
        "                    line = line.strip()\n",
        "                    if line != '':\n",
        "                        img_path, side = [x.strip() for x in line.split()]\n",
        "                        day, img = img_path.split('/')\n",
        "                        self.eval_entries.append({\n",
        "                            'day': day,\n",
        "                            'img_name': img,\n",
        "                            'person': person,\n",
        "                            'side': side\n",
        "                        })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.eval_entries)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        return self._load_sample(idx)\n",
        "\n",
        "    def _load_sample(self, i):\n",
        "        entry = self.eval_entries[i]\n",
        "        mat_path = os.path.join(self.mpii_dir, 'Data/Normalized', entry['person'], entry['day'] + '.mat')\n",
        "        mat = sio.loadmat(mat_path)\n",
        "\n",
        "        filenames = mat['filenames']\n",
        "        row = np.argwhere(filenames == entry['img_name'])[0][0]\n",
        "        side = entry['side']\n",
        "\n",
        "        img = mat['data'][side][0, 0]['image'][0, 0][row]\n",
        "        img = cv2.resize(img, (160, 96))\n",
        "        img = cv2.equalizeHist(img)\n",
        "        img = img / 255.\n",
        "        img = img.astype(np.float32)\n",
        "        if side == 'right':\n",
        "            img = np.fliplr(img)\n",
        "\n",
        "        (x, y, z) = mat['data'][side][0, 0]['gaze'][0, 0][row]\n",
        "\n",
        "        theta = np.arcsin(-y)\n",
        "        phi = np.arctan2(-x, -z)\n",
        "        gaze = np.array([-theta, phi])\n",
        "\n",
        "        return {\n",
        "            'img': img,\n",
        "            'gaze': gaze,\n",
        "            'side': side\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqBt3TfWOCIC"
      },
      "outputs": [],
      "source": [
        "def softargmax2d(input, beta=100, dtype=torch.float32):\n",
        "    *_, h, w = input.shape\n",
        "\n",
        "    input = input.reshape(*_, h * w)\n",
        "    input = nn.functional.softmax(beta * input, dim=-1)\n",
        "\n",
        "    indices_c, indices_r = np.meshgrid(\n",
        "        np.linspace(0, 1, w),\n",
        "        np.linspace(0, 1, h),\n",
        "        indexing='xy'\n",
        "    )\n",
        "\n",
        "    indices_r = torch.tensor(np.reshape(indices_r, (-1, h * w)))\n",
        "    indices_c = torch.tensor(np.reshape(indices_c, (-1, h * w)))\n",
        "\n",
        "    device = input.get_device()\n",
        "    if device >= 0:\n",
        "        indices_r = indices_r.to(device)\n",
        "        indices_c = indices_c.to(device)\n",
        "\n",
        "    result_r = torch.sum((h - 1) * input * indices_r, dim=-1)\n",
        "    result_c = torch.sum((w - 1) * input * indices_c, dim=-1)\n",
        "\n",
        "    result = torch.stack([result_r, result_c], dim=-1)\n",
        "\n",
        "    return result.type(dtype)\n",
        "\n",
        "\n",
        "def softargmax1d(input, beta=100):\n",
        "    *_, n = input.shape\n",
        "    input = nn.functional.softmax(beta * input, dim=-1)\n",
        "    indices = torch.linspace(0, 1, n)\n",
        "    result = torch.sum((n - 1) * input * indices, dim=-1)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liUth-AFOeeX"
      },
      "outputs": [],
      "source": [
        "class EyeSample:\n",
        "    def __init__(self, orig_img, img, is_left, transform_inv, estimated_radius):\n",
        "        self._orig_img = orig_img.copy()\n",
        "        self._img = img.copy()\n",
        "        self._is_left = is_left\n",
        "        self._transform_inv = transform_inv\n",
        "        self._estimated_radius = estimated_radius\n",
        "    @property\n",
        "    def orig_img(self):\n",
        "        return self._orig_img\n",
        "\n",
        "    @property\n",
        "    def img(self):\n",
        "        return self._img\n",
        "\n",
        "    @property\n",
        "    def is_left(self):\n",
        "        return self._is_left\n",
        "\n",
        "    @property\n",
        "    def transform_inv(self):\n",
        "        return self._transform_inv\n",
        "\n",
        "    @property\n",
        "    def estimated_radius(self):\n",
        "        return self._estimated_radius"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78H1AVoUOe-i"
      },
      "outputs": [],
      "source": [
        "class EyePrediction():\n",
        "    def __init__(self, eye_sample: EyeSample, landmarks, gaze):\n",
        "        self._eye_sample = eye_sample\n",
        "        self._landmarks = landmarks\n",
        "        self._gaze = gaze\n",
        "\n",
        "    @property\n",
        "    def eye_sample(self):\n",
        "        return self._eye_sample\n",
        "\n",
        "    @property\n",
        "    def landmarks(self):\n",
        "        return self._landmarks\n",
        "\n",
        "    @property\n",
        "    def gaze(self):\n",
        "        return self._gaze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UihpEjEQmnb"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GG0S2Y9Qvg9"
      },
      "outputs": [],
      "source": [
        "class HeatmapLoss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HeatmapLoss, self).__init__()\n",
        "\n",
        "    def forward(self, pred, gt):\n",
        "        loss = ((pred - gt)**2)\n",
        "        loss = torch.mean(loss, dim=(1, 2, 3))\n",
        "        return loss\n",
        "\n",
        "\n",
        "class AngularError(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AngularError, self).__init__()\n",
        "\n",
        "    def forward(self, gaze_pred, gaze):\n",
        "        loss = ((gaze_pred - gaze)**2)\n",
        "        loss = torch.mean(loss, dim=(1, 2, 3))\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rcb6HOCdQpE3"
      },
      "outputs": [],
      "source": [
        "Pool = nn.MaxPool2d\n",
        "\n",
        "\n",
        "def batchnorm(x):\n",
        "    return nn.BatchNorm2d(x.size()[1])(x)\n",
        "\n",
        "\n",
        "class Conv(nn.Module):\n",
        "    def __init__(self, inp_dim, out_dim, kernel_size=3, stride = 1, bn = False, relu = True):\n",
        "        super(Conv, self).__init__()\n",
        "        self.inp_dim = inp_dim\n",
        "        self.conv = nn.Conv2d(inp_dim, out_dim, kernel_size, stride, padding=(kernel_size-1)//2, bias=True)\n",
        "        self.relu = None\n",
        "        self.bn = None\n",
        "        if relu:\n",
        "            self.relu = nn.ReLU()\n",
        "        if bn:\n",
        "            self.bn = nn.BatchNorm2d(out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert x.size()[1] == self.inp_dim, \"{} {}\".format(x.size()[1], self.inp_dim)\n",
        "        x = self.conv(x)\n",
        "        if self.bn is not None:\n",
        "            x = self.bn(x)\n",
        "        if self.relu is not None:\n",
        "            x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, inp_dim, out_dim):\n",
        "        super(Residual, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.bn1 = nn.BatchNorm2d(inp_dim)\n",
        "        self.conv1 = Conv(inp_dim, int(out_dim/2), 1, relu=False)\n",
        "        self.bn2 = nn.BatchNorm2d(int(out_dim/2))\n",
        "        self.conv2 = Conv(int(out_dim/2), int(out_dim/2), 3, relu=False)\n",
        "        self.bn3 = nn.BatchNorm2d(int(out_dim/2))\n",
        "        self.conv3 = Conv(int(out_dim/2), out_dim, 1, relu=False)\n",
        "        self.skip_layer = Conv(inp_dim, out_dim, 1, relu=False)\n",
        "        if inp_dim == out_dim:\n",
        "            self.need_skip = False\n",
        "        else:\n",
        "            self.need_skip = True\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if self.need_skip:\n",
        "            residual = self.skip_layer(x)\n",
        "        else:\n",
        "            residual = x\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out += residual\n",
        "        return out \n",
        "\n",
        "\n",
        "class Hourglass(nn.Module):\n",
        "    def __init__(self, n, f, bn=None, increase=0):\n",
        "        super(Hourglass, self).__init__()\n",
        "        nf = f + increase\n",
        "        self.up1 = Residual(f, f)\n",
        "        # Lower branch\n",
        "        self.pool1 = Pool(2, 2)\n",
        "        self.low1 = Residual(f, nf)\n",
        "        self.n = n\n",
        "        # Recursive hourglass\n",
        "        if self.n > 1:\n",
        "            self.low2 = Hourglass(n-1, nf, bn=bn)\n",
        "        else:\n",
        "            self.low2 = Residual(nf, nf)\n",
        "        self.low3 = Residual(nf, f)\n",
        "\n",
        "    def forward(self, x):\n",
        "        up1 = self.up1(x)\n",
        "        pool1 = self.pool1(x)\n",
        "        low1 = self.low1(pool1)\n",
        "        low2 = self.low2(low1)\n",
        "        low3 = self.low3(low2)\n",
        "        up2 = nn.functional.interpolate(low3, x.shape[2:], mode='bilinear')\n",
        "        return up1 + up2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlkwlVG-Qnzv"
      },
      "outputs": [],
      "source": [
        "class Merge(nn.Module):\n",
        "    def __init__(self, x_dim, y_dim):\n",
        "        super(Merge, self).__init__()\n",
        "        self.conv = Conv(x_dim, y_dim, 1, relu=False, bn=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class EyeNet(nn.Module):\n",
        "    def __init__(self, nstack, nfeatures, nlandmarks, bn=False, increase=0, **kwargs):\n",
        "        super(EyeNet, self).__init__()\n",
        "\n",
        "        self.img_w = 160\n",
        "        self.img_h = 96\n",
        "        self.nstack = nstack\n",
        "        self.nfeatures = nfeatures\n",
        "        self.nlandmarks = nlandmarks\n",
        "\n",
        "        self.heatmap_w = self.img_w / 2\n",
        "        self.heatmap_h = self.img_h / 2\n",
        "\n",
        "        self.nstack = nstack\n",
        "        self.pre = nn.Sequential(\n",
        "            Conv(1, 64, 7, 1, bn=True, relu=True),\n",
        "            Residual(64, 128),\n",
        "            Pool(2, 2),\n",
        "            Residual(128, 128),\n",
        "            Residual(128, nfeatures)\n",
        "        )\n",
        "\n",
        "        self.pre2 = nn.Sequential(\n",
        "            Conv(nfeatures, 64, 7, 2, bn=True, relu=True),\n",
        "            Residual(64, 128),\n",
        "            Pool(2, 2),\n",
        "            Residual(128, 128),\n",
        "            Residual(128, nfeatures)\n",
        "        )\n",
        "\n",
        "        self.hgs = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                Hourglass(4, nfeatures, bn, increase),\n",
        "            ) for i in range(nstack)])\n",
        "\n",
        "        self.features = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                Residual(nfeatures, nfeatures),\n",
        "                Conv(nfeatures, nfeatures, 1, bn=True, relu=True)\n",
        "            ) for i in range(nstack)])\n",
        "\n",
        "        self.outs = nn.ModuleList([Conv(nfeatures, nlandmarks, 1, relu=False, bn=False) for i in range(nstack)])\n",
        "        self.merge_features = nn.ModuleList([Merge(nfeatures, nfeatures) for i in range(nstack - 1)])\n",
        "        self.merge_preds = nn.ModuleList([Merge(nlandmarks, nfeatures) for i in range(nstack - 1)])\n",
        "\n",
        "        self.gaze_fc1 = nn.Linear(in_features=int(nfeatures * self.img_w * self.img_h / 64 + nlandmarks*2), out_features=256)\n",
        "        self.gaze_fc2 = nn.Linear(in_features=256, out_features=2)\n",
        "\n",
        "        self.nstack = nstack\n",
        "        self.heatmapLoss = HeatmapLoss()\n",
        "        self.landmarks_loss = nn.MSELoss()\n",
        "        self.gaze_loss = nn.MSELoss()\n",
        "\n",
        "    def forward(self, imgs):\n",
        "        # imgs of size 1,ih,iw\n",
        "        x = imgs.unsqueeze(1)\n",
        "        x = self.pre(x)\n",
        "\n",
        "        gaze_x = self.pre2(x)\n",
        "        gaze_x = gaze_x.flatten(start_dim=1)\n",
        "\n",
        "        combined_hm_preds = []\n",
        "        for i in torch.arange(self.nstack):\n",
        "            hg = self.hgs[i](x)\n",
        "            feature = self.features[i](hg)\n",
        "            preds = self.outs[i](feature)\n",
        "            combined_hm_preds.append(preds)\n",
        "            if i < self.nstack - 1:\n",
        "                x = x + self.merge_preds[i](preds) + self.merge_features[i](feature)\n",
        "\n",
        "        heatmaps_out = torch.stack(combined_hm_preds, 1)\n",
        "\n",
        "        landmarks_out = softargmax2d(preds)  # N x nlandmarks x 2\n",
        "\n",
        "        # Gaze\n",
        "        gaze = torch.cat((gaze_x, landmarks_out.flatten(start_dim=1)), dim=1)\n",
        "        gaze = self.gaze_fc1(gaze)\n",
        "        gaze = nn.functional.relu(gaze)\n",
        "        gaze = self.gaze_fc2(gaze)\n",
        "\n",
        "        print(gaze.shape)\n",
        "\n",
        "        return heatmaps_out, landmarks_out, gaze\n",
        "\n",
        "    def calc_loss(self, combined_hm_preds, heatmaps, landmarks_pred, landmarks, gaze_pred, gaze):\n",
        "        combined_loss = []\n",
        "        for i in range(self.nstack):\n",
        "            combined_loss.append(self.heatmapLoss(combined_hm_preds[:, i, :], heatmaps))\n",
        "\n",
        "        heatmap_loss = torch.stack(combined_loss, dim=1)\n",
        "        landmarks_loss = self.landmarks_loss(landmarks_pred, landmarks)\n",
        "        gaze_loss = self.gaze_loss(gaze_pred, gaze)\n",
        "\n",
        "        return torch.sum(heatmap_loss), landmarks_loss, 1000 * gaze_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANdnsO91OCsx"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHFMdII9IlZH",
        "outputId": "7fae7fdc-925e-4774-8f81-3a35823654a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Set up pytorch\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(0)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4ZEOMVEIuVj"
      },
      "outputs": [],
      "source": [
        "def validate(eyenet: EyeNet, val_loader: DataLoader) -> float:\n",
        "    with torch.no_grad():\n",
        "        val_losses = []\n",
        "        for val_batch in val_loader:\n",
        "            val_imgs = val_batch['img'].float().to(device)\n",
        "            heatmaps = val_batch['heatmaps'].to(device)\n",
        "            landmarks = val_batch['landmarks'].to(device)\n",
        "            gaze = val_batch['gaze'].float().to(device)\n",
        "            heatmaps_pred, landmarks_pred, gaze_pred = eyenet.forward(val_imgs)\n",
        "            heatmaps_loss, landmarks_loss, gaze_loss = eyenet.calc_loss(\n",
        "                heatmaps_pred, heatmaps, landmarks_pred, landmarks, gaze_pred, gaze)\n",
        "            loss = 1000 * heatmaps_loss + landmarks_loss + gaze_loss\n",
        "            val_losses.append(loss.item())\n",
        "        val_loss = np.mean(val_losses)\n",
        "        val_losses_list.append(val_loss)\n",
        "        return val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hw8MnJXfIu06"
      },
      "outputs": [],
      "source": [
        "def train_epoch(epoch: int,\n",
        "                eyenet: EyeNet,\n",
        "                optimizer,\n",
        "                train_loader : DataLoader,\n",
        "                val_loader: DataLoader,\n",
        "                best_val_loss: float,\n",
        "                checkpoint_fn: str,\n",
        "                writer: SummaryWriter):\n",
        "\n",
        "    N = len(train_loader)\n",
        "    for i_batch, sample_batched in enumerate(train_loader):\n",
        "        i_batch += N * epoch\n",
        "        imgs = sample_batched['img'].float().to(device)\n",
        "        heatmaps_pred, landmarks_pred, gaze_pred = eyenet.forward(imgs)\n",
        "\n",
        "        heatmaps = sample_batched['heatmaps'].to(device)\n",
        "        landmarks = sample_batched['landmarks'].float().to(device)\n",
        "        gaze = sample_batched['gaze'].float().to(device)\n",
        "\n",
        "        heatmaps_loss, landmarks_loss, gaze_loss = eyenet.calc_loss(\n",
        "            heatmaps_pred, heatmaps, landmarks_pred, landmarks, gaze_pred, gaze)\n",
        "\n",
        "        loss = 1000 * heatmaps_loss + landmarks_loss + gaze_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        hm = np.mean(heatmaps[-1, 8:16].cpu().detach().numpy(), axis=0)\n",
        "        hm_pred = np.mean(heatmaps_pred[-1, -1, 8:16].cpu().detach().numpy(), axis=0)\n",
        "        norm_hm = cv2.normalize(hm, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "        norm_hm_pred = cv2.normalize(hm_pred, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "\n",
        "        if i_batch % 20 == 0:\n",
        "            cv2.imwrite('true.jpg', norm_hm * 255)\n",
        "            cv2.imwrite('pred.jpg', norm_hm_pred * 255)\n",
        "            cv2.imwrite('eye.jpg', sample_batched['img'].numpy()[-1] * 255)\n",
        "\n",
        "        writer.add_scalar(\"Training heatmaps loss\", heatmaps_loss.item(), i_batch)\n",
        "        writer.add_scalar(\"Training landmarks loss\", landmarks_loss.item(), i_batch)\n",
        "        writer.add_scalar(\"Training gaze loss\", gaze_loss.item(), i_batch)\n",
        "        writer.add_scalar(\"Training loss\", loss.item(), i_batch)\n",
        "\n",
        "        train_losses_list.append(loss.item())\n",
        "\n",
        "        if i_batch > 0 and i_batch % 20 == 0:\n",
        "            val_loss = validate(eyenet=eyenet, val_loader=val_loader)\n",
        "            writer.add_scalar(\"validation loss\", val_loss, i_batch)\n",
        "            print('Epoch', epoch, 'Validation loss', val_loss)\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                torch.save({\n",
        "                    'nstack': eyenet.nstack,\n",
        "                    'nfeatures': eyenet.nfeatures,\n",
        "                    'nlandmarks': eyenet.nlandmarks,\n",
        "                    'best_val_loss': best_val_loss,\n",
        "                    'model_state_dict': eyenet.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                }, checkpoint_fn)\n",
        "\n",
        "    return best_val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwAbhlPzIz0U"
      },
      "outputs": [],
      "source": [
        "def train(eyenet: EyeNet, optimizer, nepochs: int, best_val_loss: float, checkpoint_fn: str):\n",
        "    timestr = datetime.now().strftime(\"%m%d%Y-%H%M%S\")\n",
        "    writer = SummaryWriter(f'runs/eyenet-{timestr}')\n",
        "    dataset = UnityEyesDataset('/content/drive/MyDrive/imgs/')\n",
        "    N = len(dataset)\n",
        "    print(N)\n",
        "    VN = 160\n",
        "    TN = N - VN\n",
        "    train_set, val_set = torch.utils.data.random_split(dataset, (TN, VN))\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=32, shuffle=True)\n",
        "\n",
        "    for i in range(nepochs):\n",
        "        best_val_loss = train_epoch(epoch=i,\n",
        "                                    eyenet=eyenet,\n",
        "                                    optimizer=optimizer,\n",
        "                                    train_loader=train_loader,\n",
        "                                    val_loader=val_loader,\n",
        "                                    best_val_loss=best_val_loss,\n",
        "                                    checkpoint_fn=checkpoint_fn,\n",
        "                                    writer=writer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqEWqBwDI2l0"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    learning_rate = 4 * 1e-4\n",
        "    nstack = 3\n",
        "    nfeatures = 32\n",
        "    nlandmarks = 34\n",
        "    nepochs = 10\n",
        "    best_val_loss = float('inf')\n",
        "    eyenet = EyeNet(nstack=nstack, nfeatures=nfeatures, nlandmarks=nlandmarks).to(device)\n",
        "    optimizer = torch.optim.Adam(eyenet.parameters(), lr=learning_rate)\n",
        "    out = 'checkpoint.pt'\n",
        "\n",
        "    train(\n",
        "        eyenet=eyenet,\n",
        "        optimizer=optimizer,\n",
        "        nepochs=nepochs,\n",
        "        best_val_loss=best_val_loss,\n",
        "        checkpoint_fn=out\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6VyE5kW1dqA"
      },
      "outputs": [],
      "source": [
        "train_losses_list = []\n",
        "val_losses_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IWc-TeXlRmCj"
      },
      "outputs": [],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hvjgxzmj0pPu"
      },
      "outputs": [],
      "source": [
        "len(train_losses_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WH14n4Cy0sJu"
      },
      "outputs": [],
      "source": [
        "len(val_losses_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bdZn4zWrRqzz"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 1, figsize=(8, 8))\n",
        "\n",
        "# axs.plot(np.arange(1, 21), train_losses_list, color='blue', label='Training Loss')\n",
        "axs.plot(np.arange(1, 72), val_losses_list, color='red', label='Validation Loss')\n",
        "axs.set_xlabel('# of epochs')\n",
        "axs.set_ylabel('Loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.savefig('loss_graph.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L58DdyKT0wv9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}